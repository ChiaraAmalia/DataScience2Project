{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In questo file andiamo a fare il task di clusterizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for basic mathematics operation \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"none\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adesso vado a caricare il dataset ma solo con le due colonne d'interesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2190888, 4)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('DataSet\\out.csv')\n",
    "#display(data.head())\n",
    "\n",
    "# take only annual income and spending score\n",
    "x = data.iloc[:, [0,8,9,13]].values\n",
    "\n",
    "# let's check the shape of x\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devo fare ETL, devo eliminare i valore Nan nel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\Desktop\\UniversitÃ \\Data science\\Progetti\\ProgettoPython\\DataScience2Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "# Cambio della cartella attuale nella cartella in cui si trova il file .py\n",
    "path_file = os.path.abspath(os.getcwd())\n",
    "print(path_file)\n",
    "os.chdir(path_file)\n",
    "\n",
    "path_cartella = r\"\\archive\\csvs_per_year\\csvs_per_year\"\n",
    "\n",
    "path = path_file + path_cartella"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per comoditÃ  carico direttamente tutti i file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vado a caricare tutte le tabelle del mio dataset\n",
    "\n",
    "madrid2008 = pd.read_csv(path+\"\\madrid_2008.csv\")\n",
    "madrid2009 = pd.read_csv(path+\"\\madrid_2009.csv\")\n",
    "madrid2010 = pd.read_csv(path+\"\\madrid_2010.csv\")\n",
    "madrid2011 = pd.read_csv(path+\"\\madrid_2011.csv\")\n",
    "madrid2012 = pd.read_csv(path+\"\\madrid_2012.csv\")\n",
    "madrid2013 = pd.read_csv(path+\"\\madrid_2013.csv\")\n",
    "madrid2014 = pd.read_csv(path+\"\\madrid_2014.csv\")\n",
    "madrid2015 = pd.read_csv(path+\"\\madrid_2015.csv\")\n",
    "madrid2016 = pd.read_csv(path+\"\\madrid_2016.csv\")\n",
    "madrid2017 = pd.read_csv(path+\"\\madrid_2017.csv\")\n",
    "madrid2018 = pd.read_csv(path+\"\\madrid_2018.csv\")\n",
    "station = pd.read_csv('DataSet\\stations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per ogni anno e per ogni stazione calcolo la media troncata e la sostituisco ai valori Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_10076\\2544690094.py:1: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  full = pd.Series()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full = pd.Series()\n",
    "'''for y in station['id'].values:\n",
    "    onlyOne=madrid2008[madrid2008[\"station\"].astype(str).str.contains(str(y))]\n",
    "    display('sono qui all inizio')\n",
    "    display(onlyOne['PM10'].count())\n",
    "    newValue= stats.trim_mean(onlyOne['PM10'].values,0.1) # La faccio qui \n",
    "    if(not math.isnan(newValue)):\n",
    "        onlyOne = onlyOne['PM10'].fillna(newValue) # Questo mette la media al posto dei nulli\n",
    "        display(onlyOne.count())\n",
    "        display('sono qui alla fine')\n",
    "        full = pd.concat([full,onlyOne])'''\n",
    "    \n",
    "onlyOne=madrid2008[madrid2008[\"station\"].astype(str).str.contains(str('28079004'))]\n",
    "display(onlyOne['PM10'].isna().sum())\n",
    "'''onlyOne2=madrid2008[madrid2008[\"station\"].astype(str).str.contains(str('28079008'))]\n",
    "newValue= stats.trim_mean(onlyOne['PM10'].values,0.1)\n",
    "newValue2= stats.trim_mean(onlyOne2['PM10'].values,0.1)\n",
    "if(not math.isnan(newValue)):\n",
    "    onlyOne = onlyOne['PM10'].fillna(newValue)\n",
    "if(not math.isnan(newValue2)):\n",
    "    onlyOne2 = onlyOne2['PM10'].fillna(newValue)\n",
    "\n",
    "df = full.to_frame(name='PM10')\n",
    "display(df.isna().sum())\n",
    "display(df.size)'''\n",
    "\n",
    "#display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qui vado a fare le operazioni per calcolare il K migliore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m11\u001b[39m):\n\u001b[0;32m      3\u001b[0m     km \u001b[39m=\u001b[39m KMeans(n_clusters \u001b[39m=\u001b[39m i, init \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mk-means++\u001b[39m\u001b[39m'\u001b[39m, max_iter \u001b[39m=\u001b[39m \u001b[39m300\u001b[39m, n_init \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, random_state \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     km\u001b[39m.\u001b[39;49mfit(x)\n\u001b[0;32m      5\u001b[0m     distortions\u001b[39m.\u001b[39mappend(km\u001b[39m.\u001b[39minertia_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1367\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1342\u001b[0m     \u001b[39m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[0;32m   1343\u001b[0m \n\u001b[0;32m   1344\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1366\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1367\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1368\u001b[0m         X,\n\u001b[0;32m   1369\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1370\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[0;32m   1371\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1372\u001b[0m         copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy_x,\n\u001b[0;32m   1373\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1374\u001b[0m     )\n\u001b[0;32m   1376\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params(X)\n\u001b[0;32m   1377\u001b[0m     random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m         )\n\u001b[0;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[0;32m    900\u001b[0m             array,\n\u001b[0;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    904\u001b[0m         )\n\u001b[0;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[0;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m             )\n\u001b[1;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[0;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "distortions = []\n",
    "for i in range(1, 11):\n",
    "    km = KMeans(n_clusters = i, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)\n",
    "    km.fit(x)\n",
    "    distortions.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stampo il grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(range(1, 11), distortions)\n",
    "plt.title('K-Means Clustering(The Elbow Method)', fontsize = 20)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919c18adca473b496926cbcc6d5129551fb55bb1642c0f0de4be834ae80622d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
